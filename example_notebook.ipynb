{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGxs8X2yUVHF"
      },
      "outputs": [],
      "source": [
        "!pip install mushroom_rl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nblKGPDVrg1"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y \\\n",
        "    libgl1-mesa-dev \\\n",
        "    libgl1-mesa-glx \\\n",
        "    libglew-dev \\\n",
        "    libosmesa6-dev \\\n",
        "    software-properties-common\n",
        "\n",
        "!apt-get install -y patchelf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpgOu2PEVvJs",
        "outputId": "b5699dcb-7cb4-46e2-9052-950cf7cc483f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: free-mujoco-py in /usr/local/lib/python3.7/dist-packages (2.1.6)\n",
            "Requirement already satisfied: imageio<3.0.0,>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (2.19.0)\n",
            "Requirement already satisfied: glfw<2.0.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (1.12.0)\n",
            "Requirement already satisfied: Cython<0.30.0,>=0.29.24 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (0.29.28)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (1.15.0)\n",
            "Requirement already satisfied: fasteners==0.15 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (0.15)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.3 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (1.21.6)\n",
            "Requirement already satisfied: monotonic>=0.1 in /usr/local/lib/python3.7/dist-packages (from fasteners==0.15->free-mujoco-py) (1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fasteners==0.15->free-mujoco-py) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi<2.0.0,>=1.15.0->free-mujoco-py) (2.21)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.7/dist-packages (from imageio<3.0.0,>=2.9.0->free-mujoco-py) (9.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install free-mujoco-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvSkH5PUWKbY"
      },
      "source": [
        "**Now you need to restart the runtime as numpy is apparently automatically imported...**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-umLoul3Vz9u"
      },
      "outputs": [],
      "source": [
        "import mujoco_py\n",
        "import gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTJwoXUgT5Q6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from mushroom_rl.core import Core, Logger\n",
        "from mushroom_rl.environments.gym_env import Gym\n",
        "from mushroom_rl.policy import OrnsteinUhlenbeckPolicy\n",
        "from mushroom_rl.utils.dataset import compute_J, parse_dataset\n",
        "from tqdm import trange"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Optional if you load the code into your drive**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0RGcy13Qq3Cx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqLQTdT2UCf3",
        "outputId": "2478acc3-0871-47b5-eef0-89aa406d0752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9wJFpHBU2gH",
        "outputId": "cdceb6f9-2491-4b71-a5d6-c0b6df076c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/uncertainty-buffer\n"
          ]
        }
      ],
      "source": [
        "%cd ./drive/MyDrive/Colab\\ Notebooks/uncertainty-buffer/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **If the code is not in drive, continue here**"
      ],
      "metadata": {
        "id": "0jwqMcgGrBat"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efuDRs1BUzt7"
      },
      "outputs": [],
      "source": [
        "from agents.mult_head_sac import MultiHeadSAC\n",
        "from agents.multi_head_ddpg import MultiHeadDDPG\n",
        "from agents.multi_head_TD3 import MultiHeadTD3\n",
        "from networks.networks import (\n",
        "    ActorNetwork,\n",
        "    MultiHeadCriticNetwork,\n",
        "    MultiHeadCriticNetwork_noise,\n",
        "    SACActorNetwork,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbsI5wzHVR-a"
      },
      "outputs": [],
      "source": [
        "def experiment(\n",
        "    alg,\n",
        "    environment,\n",
        "    n_epochs,\n",
        "    n_steps,\n",
        "    n_steps_test,\n",
        "    buffer_strategy,\n",
        "    buffer_size,\n",
        "    buffer_alpha,\n",
        "    buffer_beta,\n",
        "):\n",
        "    # np.random.seed()\n",
        "\n",
        "    logger = Logger(alg.__name__, results_dir=None)\n",
        "    logger.strong_line()\n",
        "    logger.info(\"Experiment Algorithm: \" + alg.__name__)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "\n",
        "    # MDP\n",
        "    horizon = 100\n",
        "    gamma = 0.99\n",
        "    env_name = environment\n",
        "    mdp = Gym(env_name, horizon, gamma)\n",
        "\n",
        "    # Policy\n",
        "    policy_class = OrnsteinUhlenbeckPolicy\n",
        "    policy_params = dict(sigma=np.ones(1) * 0.2, theta=0.15, dt=1e-2)\n",
        "\n",
        "    # Settings\n",
        "    initial_replay_size = 300\n",
        "\n",
        "    max_replay_size = buffer_size\n",
        "    batch_size = 256\n",
        "    n_features = 256\n",
        "    tau = 0.001\n",
        "    warmup_transitions = 1000\n",
        "    use_noise = False\n",
        "    if use_noise:\n",
        "        critic_network = MultiHeadCriticNetwork_noise\n",
        "    else:\n",
        "        critic_network = MultiHeadCriticNetwork\n",
        "\n",
        "    if \"SAC\" in alg.__name__ or \"sac\" in alg.__name__:\n",
        "        actor_network = SACActorNetwork\n",
        "    else:\n",
        "        actor_network = ActorNetwork\n",
        "\n",
        "    # Approximator\n",
        "    actor_input_shape = mdp.info.observation_space.shape\n",
        "    actor_params = dict(\n",
        "        network=actor_network,\n",
        "        n_features=n_features,\n",
        "        input_shape=actor_input_shape,\n",
        "        output_shape=mdp.info.action_space.shape,\n",
        "        use_cuda=use_cuda,\n",
        "    )\n",
        "\n",
        "    actor_sigma_params = dict(\n",
        "        network=actor_network,\n",
        "        n_features=n_features,\n",
        "        input_shape=actor_input_shape,\n",
        "        output_shape=mdp.info.action_space.shape,\n",
        "        use_cuda=use_cuda,\n",
        "    )\n",
        "\n",
        "    if \"SAC\" in alg.__name__ or \"sac\" in alg.__name__:\n",
        "        actor_optimizer = {\"class\": optim.Adam, \"params\": {\"lr\": 3e-4}}\n",
        "    else:\n",
        "        actor_optimizer = {\"class\": optim.Adam, \"params\": {\"lr\": 0.001}}\n",
        "\n",
        "    critic_input_shape = (actor_input_shape[0] + mdp.info.action_space.shape[0],)\n",
        "    critic_params = dict(\n",
        "        network=critic_network,\n",
        "        optimizer={\"class\": optim.Adam, \"params\": {\"lr\": 3e-4}},\n",
        "        loss=F.mse_loss,\n",
        "        n_features=n_features,\n",
        "        input_shape=critic_input_shape,\n",
        "        output_shape=(1,),\n",
        "        head_prob=0.7,\n",
        "        use_cuda=use_cuda,\n",
        "    )\n",
        "\n",
        "    # Agent\n",
        "    if \"SAC\" in alg.__name__ or \"sac\" in alg.__name__:\n",
        "        tau = 0.005\n",
        "        lr_alpha = 3e-4\n",
        "        agent = alg(\n",
        "            mdp.info,\n",
        "            actor_params,\n",
        "            actor_sigma_params,\n",
        "            actor_optimizer,\n",
        "            critic_params,\n",
        "            batch_size,\n",
        "            initial_replay_size,\n",
        "            max_replay_size,\n",
        "            warmup_transitions,\n",
        "            tau,\n",
        "            lr_alpha,\n",
        "            critic_fit_params=None,\n",
        "            buffer_strategy=buffer_strategy,\n",
        "            buffer_alpha=buffer_alpha,\n",
        "            buffer_beta=buffer_beta,\n",
        "        )\n",
        "    else:\n",
        "        agent = alg(\n",
        "            mdp.info,\n",
        "            policy_class,\n",
        "            policy_params,\n",
        "            actor_params,\n",
        "            actor_optimizer,\n",
        "            critic_params,\n",
        "            batch_size,\n",
        "            initial_replay_size,\n",
        "            max_replay_size,\n",
        "            tau,\n",
        "            warmup_transitions=warmup_transitions,\n",
        "            buffer_strategy=buffer_strategy,\n",
        "        )\n",
        "\n",
        "    # Algorithm\n",
        "    core = Core(agent, mdp)\n",
        "\n",
        "    core.learn(n_steps=initial_replay_size, n_steps_per_fit=initial_replay_size)\n",
        "\n",
        "    # RUN\n",
        "    dataset = core.evaluate(n_steps=n_steps_test, render=False)\n",
        "    J = np.mean(compute_J(dataset, gamma))\n",
        "    R = np.mean(compute_J(dataset))\n",
        "\n",
        "    logger.epoch_info(0, J=J, R=R)\n",
        "    rewards = list()\n",
        "    k = 1\n",
        "    filename = f\"{alg.__name__}{k}_{env_name}_{buffer_strategy}_noise{use_noise}_alpha{buffer_alpha}_beta{buffer_beta}_size{buffer_size}.npy\"\n",
        "    while os.path.isfile(filename):\n",
        "        filename = f\"{alg.__name__}{k}_{env_name}_{buffer_strategy}_noise{use_noise}_alpha{buffer_alpha}_beta{buffer_beta}_size{buffer_size}.npy\"\n",
        "        k += 1\n",
        "    print(f\"save file {filename}\")\n",
        "    # Create empty file as placeholder to prevent overwriting\n",
        "    with open(filename, mode=\"a\"):\n",
        "        pass\n",
        "\n",
        "    s = None\n",
        "    for n in trange(n_epochs, leave=False):\n",
        "        core.learn(n_steps=n_steps, n_steps_per_fit=1)\n",
        "        dataset = core.evaluate(n_steps=n_steps_test, render=False)\n",
        "        s, *_ = parse_dataset(dataset)\n",
        "        J = np.mean(compute_J(dataset, gamma))\n",
        "        R = np.mean(compute_J(dataset))\n",
        "        if \"SAC\" in alg.__name__:\n",
        "            E = agent.policy.entropy(s)\n",
        "        else:\n",
        "            E = None\n",
        "        rewards.append(R)\n",
        "        if n % 100 == 0:\n",
        "            # agent.save_buffer_snapshot(alg_name=alg.__name__,  epoch=n+1)\n",
        "            np.save(filename, np.array(rewards))\n",
        "        logger.epoch_info(n + 1, J=J, R=R, entropy=E)\n",
        "    np.save(filename, np.array(rewards))\n",
        "    # logger.info('Press a button to visualize pendulum')\n",
        "    # input()\n",
        "    # core.evaluate(n_episodes=5, render=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define Hyperparameters"
      ],
      "metadata": {
        "id": "kmzxM8oBrhrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alg = MultiHeadSAC  # Choose one out of [MultiHeadSAC, MultiHeadTD3, MultiHeadDDPG]\n",
        "env = \"Humanoid-v3\" \n",
        "buffer_strategy = \"uniform\"\n",
        "buffer_size = 1e5\n",
        "n_epochs = 1000\n",
        "n_experiments = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "5482K_k0rhNb",
        "outputId": "e87ddfbc-1028-4fde-a7e9-47df1ce91ee6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-be559aa6f7ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadSAC\u001b[0m \u001b[0;31m# Choose one out of [MultiHeadSAC, MultiHeadTD3, MultiHeadDDPG]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'MultiHeadSAC' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Yt11mOMoLpo9"
      },
      "outputs": [],
      "source": [
        "for _ in range(n_experiments):\n",
        "        experiment(\n",
        "            alg=alg,\n",
        "            environment=env,\n",
        "            n_epochs=n_epochs,\n",
        "            n_steps=1000,\n",
        "            n_steps_test=2000,\n",
        "            buffer_strategy=buffer_strategy,\n",
        "            buffer_size=int(buffer_size),\n",
        "            buffer_alpha=1,\n",
        "            buffer_beta=1,\n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "example_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}